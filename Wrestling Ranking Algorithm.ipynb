{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in full matches and wrestlers dataframes\n",
    "full_matches = pd.read_csv('MATCHES.csv').drop(columns=\"Unnamed: 0\")\n",
    "full_wrestlers = pd.read_csv('WRESTLERS.csv').drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches.shape # number of matches, recorded match variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wrestlers.shape # number of wrestlers, recorded wrestler variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wrestlers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wrestlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop matches decided by useless wincons like forfeit or bye (ASSUMPTION: should have no effect on ranking the wrestlers)\n",
    "bad_wins = ['Forfeit','Injury Default','Medical Forfeit','Bye','Disqualified','Default','No Contest']\n",
    "win_filter = [win not in bad_wins for win in full_matches[\"Victory Type (L)\"]]\n",
    "MATCHES = full_matches.loc[win_filter].drop_duplicates().reset_index(drop=True) # dedupe seems to work now\n",
    "# Go back and check if dedupe is removing more than it should -- maybe not distinguishing multiple bouts on same day\n",
    "MATCHES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy infoscrape function from Wrestling Tables notebook\n",
    "\n",
    "def infoscrape(fullname,df):\n",
    "    '''infoscrape receives full name of wrestler and matches dataframe\n",
    "    and collects wrestler info from dataset'''\n",
    "\n",
    "    # Initialize values of interest\n",
    "    weight_class = 0\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    matches = 0\n",
    "    school = ''\n",
    "    school_code = ''\n",
    "    first_name = ''\n",
    "    last_name = ''\n",
    "    \n",
    "    # Find observations corresponding to wrestler name\n",
    "    win_id = df['Winner Full Name'] == fullname\n",
    "    loss_id = df['Loser Full Name'] == fullname\n",
    "    winning_matches = df.loc[win_id,:]\n",
    "    losing_matches = df.loc[loss_id,:]\n",
    "    \n",
    "    # Split full name\n",
    "    first_name, last_name = fullname.split(' ',1)\n",
    "    \n",
    "    # Counting stats (should check if names show in correct columns for forfeits, byes, etc.)\n",
    "    wins = sum(win_id)\n",
    "    losses = sum(loss_id)\n",
    "    matches = wins+losses\n",
    "    \n",
    "    # Extract weight class, school, etc.\n",
    "    win_weight = winning_matches['Weight Class'].unique()\n",
    "    loss_weight = losing_matches['Weight Class'].unique()\n",
    "    \n",
    "    if win_weight.size > 0: # Avoiding 'if win_weight:' because it gives truth amibiguity warning\n",
    "        weight_class = int(win_weight[0])\n",
    "    else: # !!!Still need to add consideration for multiple weight classes!!!\n",
    "        weight_class = int(loss_weight[0])\n",
    "        \n",
    "    win_school = winning_matches['Winner School (L)'].unique()\n",
    "    win_school_code = winning_matches['Winner School (S)'].unique()\n",
    "    loss_school = losing_matches['Loser School (L)'].unique()\n",
    "    loss_school_code = losing_matches['Loser School (S)'].unique()\n",
    "    \n",
    "    if win_school.size > 0: # Avoiding 'if win_school:' because it gives truth amibiguity warning\n",
    "        school = win_school[0]\n",
    "        school_code = win_school_code[0]\n",
    "    else: \n",
    "        school = loss_school[0]\n",
    "        school_code = loss_school_code[0]\n",
    "        \n",
    "    # Return list of extracted data \n",
    "    return({'First Name':first_name,'Last Name':last_name,'Full Name':fullname,\n",
    "            'School Name':school,'School Code':school_code,\n",
    "            'Weight Class':weight_class,'Wins':wins,'Losses':losses,'Matches':matches})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remake wrestlers df\n",
    "# Note: union of winner/loser full names is set of all wrestlers in dataset\n",
    "wrestlers = set(MATCHES['Winner Full Name']) | set(MATCHES['Loser Full Name'])\n",
    "wrestlers = [x for x in wrestlers if x==x] # remove nan, convert to list\n",
    "wrestler_data = [infoscrape(wrestler,MATCHES) for wrestler in wrestlers]\n",
    "WRESTLERS = pd.DataFrame(wrestler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRESTLERS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create train and test data split by date of wrestling events\n",
    "# Note: research paper trained on one weight class and tested on all the rest.\n",
    "# Why this is a big separate function: have to remake wrestlers dataframe from filtered matches dataframe\n",
    "\n",
    "def train_test_split(match_data, wrestler_data=None, split_method='date',\n",
    "                    earliest=None, latest=None, train_size=0.75):\n",
    "    '''train_test_split creates train and test data using given match data.\n",
    "    Can split by date range for train set or desired train data size (default is date).\n",
    "    Train_size is between 0 and 1. earliest/latest are dates in format YYYYMMDD.\n",
    "    Returns dict of match_train, match_test, wrestler_train, wrestler_test.'''\n",
    "    \n",
    "    event_dates = match_data[\"Event Date\"]\n",
    "    \n",
    "    # Default dates\n",
    "    if earliest is None:\n",
    "        earliest = min(event_dates)\n",
    "    if latest is None:\n",
    "        latest = max(event_dates)\n",
    "    \n",
    "    # Handle input exceptions        \n",
    "    if latest > max(event_dates):\n",
    "        raise ValueError('Invalid indexing: latest ({}) cannot be after most recent event ({})'\\\n",
    "                         .format(latest,max(event_dates)))\n",
    "    if earliest >= latest:\n",
    "        raise ValueError('Invalid indexing: earliest ({}) must be less than latest ({})'\\\n",
    "                         .format(earliest,latest))\n",
    "        \n",
    "    # Train-Test Split\n",
    "    \n",
    "    if split_method == 'size': # split by train_size\n",
    "        \n",
    "        indices = match_data.index.values\n",
    "        n = len(indices)\n",
    "        train_start = int(np.quantile(indices,q=1-train_size))\n",
    "        train_id = range(train_start,n)\n",
    "        test_id = range(0,train_start)\n",
    "        match_train = match_data.iloc[train_id,:]\n",
    "        match_test = match_data.iloc[test_id,:]\n",
    "        \n",
    "    if split_method == 'date': # split by date range\n",
    "        \n",
    "        date_range = range(earliest,latest+1)\n",
    "        train_bool = [date in date_range for date in event_dates]\n",
    "        test_bool = [not index for index in train_bool]\n",
    "        match_train = match_data.loc[train_bool]\n",
    "        match_test = match_data.loc[test_bool]\n",
    "        \n",
    "        \n",
    "    # Name wrestlers to train or test sets\n",
    "    wrestler_names_train = set(match_train['Winner Full Name']) | set(match_train['Loser Full Name'])\n",
    "    wrestler_names_train = [x for x in wrestler_names_train if x==x] # remove nan, convert to list\n",
    "    \n",
    "    # Not sure if making wrestler test set like this makes total sense but I'll do it for now\n",
    "    # Maybe because of cumulative stats, wrestler test set is always up-to-date full wrestler data?\n",
    "    wrestler_names_test = set(match_test['Winner Full Name']) | set(match_test['Loser Full Name'])\n",
    "    wrestler_names_test = [x for x in wrestler_names_test if x==x] # remove nan, convert to list\n",
    "\n",
    "    # Call infoscrape to construct wrestler dataframes\n",
    "    wrestler_train = [infoscrape(wrestler,match_train) for wrestler in wrestler_names_train]\n",
    "    wrestler_train = pd.DataFrame(wrestler_train)\n",
    "    wrestler_test = [infoscrape(wrestler,match_test) for wrestler in wrestler_names_test]\n",
    "    wrestler_test = pd.DataFrame(wrestler_test)\n",
    "    \n",
    "    # Store train/test splits in dict\n",
    "    train_test_dict = {\"match_train\":match_train,\"match_test\":match_test,\n",
    "                      \"wrestler_train\":wrestler_train,\"wrestler_test\":wrestler_test}\n",
    "    \n",
    "    return(train_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(arr, K): \n",
    "    idx = (np.abs(arr - K)).argmin() \n",
    "    return(arr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_perc_pred(wrestler1,wrestler2,wrestler_train,wrestler_test,match_train,match_test):\n",
    "    '''win_perc_pred makes a simple prediction that the winner of a match between\n",
    "    wrestler1 and wrestler2 will be the wrestler with the higher win percentage. Uses wrestlers' fullnames.'''\n",
    "    \n",
    "    # Note: this predictor doesn't use match data for now, but I want to \n",
    "    # keep the algorithm inputs consistent for evaluation --> alg  args dict\n",
    "    \n",
    "    # log_dict to track when defaulting to school WP or matches WP, or other info tidbits\n",
    "    \n",
    "    # add confidence measure based on difference in WPs\n",
    "    \n",
    "    # Wrestler 1\n",
    "    wrestler1_bool = wrestler_train[\"Full Name\"]==wrestler1 # should add school clarification step for same names\n",
    "    \n",
    "    if sum(wrestler1_bool) == 0: # wrestler not in train set, try to use their school's average WP\n",
    "        \n",
    "        wrestler1_bool = wrestler_test[\"Full Name\"]==wrestler1\n",
    "        school = wrestler_test.loc[wrestler1_bool][\"School Name\"].values[0]\n",
    "            \n",
    "        if sum(wrestler_train[\"School Name\"]==school) == 0: # No other wrestlers from school in data :( \n",
    "            # Try using average win perc of all wrestlers with same number of matches (experience counts!)\n",
    "            \n",
    "            test_match_num = wrestler_test.loc[wrestler1_bool][\"Matches\"].values[0]\n",
    "            wrestlers_by_matches = wrestler_train.groupby(\"Matches\")\n",
    "            wins_by_match = wrestlers_by_matches[\"Wins\"].mean()\n",
    "            train_match_num = closest(wins_by_match.index.values,test_match_num)            \n",
    "            win_perc_1 = wins_by_match[train_match_num] / train_match_num\n",
    "            \n",
    "        else: # School WP\n",
    "            wrestlers_by_school = wrestler_train.groupby(\"School Name\")\n",
    "            win_perc_1 = wrestlers_by_school[\"Wins\"].mean()[school] / wrestlers_by_school[\"Matches\"].mean()[school]\n",
    "\n",
    "    else: # wrestler 1 in train set, has their own WP\n",
    "        win_perc_1 = wrestler_train.loc[wrestler1_bool][\"Wins\"] / wrestler_train.loc[wrestler1_bool][\"Matches\"]\n",
    "        win_perc_1 = win_perc_1.values[0]\n",
    "\n",
    "        \n",
    "    # Wrestler 2\n",
    "    wrestler2_bool = wrestler_train[\"Full Name\"]==wrestler2 # should add school clarification step for same names\n",
    "    \n",
    "    if sum(wrestler2_bool) == 0: # wrestler not in train set, try to use their school's average WP\n",
    "    \n",
    "        wrestler2_bool = wrestler_test[\"Full Name\"]==wrestler2\n",
    "        school = wrestler_test.loc[wrestler2_bool][\"School Name\"].values[0]\n",
    "        \n",
    "        if sum(wrestler_train[\"School Name\"]==school) == 0: # No other wrestlers from school in data :( \n",
    "            # Try using average win perc of all wrestlers with same/closest number of matches (experience counts!)\n",
    "\n",
    "            test_match_num = wrestler_test.loc[wrestler2_bool][\"Matches\"].values[0]\n",
    "            wrestlers_by_matches = wrestler_train.groupby(\"Matches\")\n",
    "            wins_by_match = wrestlers_by_matches[\"Wins\"].mean()\n",
    "            train_match_num = closest(wins_by_match.index.values,test_match_num)            \n",
    "            win_perc_2 = wins_by_match[train_match_num] / train_match_num\n",
    "        \n",
    "        else: # School WP\n",
    "            wrestlers_by_school = wrestler_train.groupby(\"School Name\")\n",
    "            win_perc_2 = wrestlers_by_school[\"Wins\"].mean()[school] / wrestlers_by_school[\"Matches\"].mean()[school]\n",
    "            \n",
    "    else: # wrestler 2 in train set, has their own WP\n",
    "        win_perc_2 = wrestler_train.loc[wrestler2_bool][\"Wins\"] / wrestler_train.loc[wrestler2_bool][\"Matches\"]\n",
    "        win_perc_2 = win_perc_2.values[0]\n",
    "\n",
    "    \n",
    "    # Do we want a minimal difference to declare a decision?\n",
    "    wp_diff = abs(win_perc_1 - win_perc_2) \n",
    "    # Reformat this into a more general confidence measure -> e.g. 0.0-0.25 == \"*\", 0.25-0.5 == \"**\", etc.\n",
    "    \n",
    "    if win_perc_1 > win_perc_2:\n",
    "        return({\"Winner\":wrestler1,\"WP_diff\":wp_diff})\n",
    "    elif win_perc_1 == win_perc_2:\n",
    "        return({\"Winner\":None,\"WP_diff\":wp_diff}) # TODO: Track these in validation\n",
    "    else:\n",
    "        return({\"Winner\":wrestler2,\"WP_diff\":wp_diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchmaker(match_test):\n",
    "    '''matchmaker takes in match test data and returns a list of \n",
    "    the associated wrestler matchup pairs'''\n",
    "    \n",
    "    \n",
    "    test_matchups = []\n",
    "    \n",
    "    for i in range(0,match_test.shape[0]):\n",
    "        match = match_test.loc[i]\n",
    "        w1 = match[\"Winner Full Name\"]\n",
    "        w2 = match[\"Loser Full Name\"]\n",
    "        \n",
    "        # nan entry -> just have wrestler go against himself for now (should result in no winner)\n",
    "        # no option for both nan, but that is a datapoint I don't even want\n",
    "        if w1!=w1:\n",
    "            w1 = w2\n",
    "        elif w2!=w2:\n",
    "            w2 = w1\n",
    "        \n",
    "        test_matchups.append((w1,w2))\n",
    "        \n",
    "    return(test_matchups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm(algorithm,match_train,match_test,wrestler_train,wrestler_test):\n",
    "    '''test_algorithm implements a given algorithm using given wrestler and match \n",
    "    train/test data and returns prediction accuracy'''\n",
    "    \n",
    "    # Extract matchups from test matches\n",
    "    test_matchups = matchmaker(match_test)\n",
    "\n",
    "    # True and predicted winners\n",
    "    true_winners = match_test[\"Winner Full Name\"] \n",
    "    pred_output = [algorithm(W1,W2,wrestler_train,wrestler_test,match_train,match_test) for W1,W2 in test_matchups]\n",
    "    pred_winners = [output[\"Winner\"] for output in pred_output]\n",
    "    pred_confidences = [output[\"WP_diff\"] for output in pred_output] # make this more general for new algs\n",
    "    \n",
    "    # Calculate prediction accuracy, save incorrect pred info\n",
    "    pred_results = true_winners == pred_winners\n",
    "    incorrect_preds = match_test.loc[true_winners != pred_winners,:]\n",
    "    n = len(pred_results)\n",
    "    correct = sum(pred_results)\n",
    "    incorrect = n - correct\n",
    "    pred_accuracy = pred_results.mean()\n",
    "    \n",
    "    return({\"Accuracy\":pred_accuracy,\"NumCorrect\":correct,\"NumIncorrect\":incorrect,\"N\":n,\n",
    "           \"WrongPreds\":incorrect_preds, \"PredConfidences\":pred_confidences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if functions do their job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train/test sets\n",
    "train_test_dict = train_test_split(MATCHES,split_method='size',train_size=0.8) # takes a minute because infoscrape function\n",
    "match_train = train_test_dict[\"match_train\"]\n",
    "wrestler_train = train_test_dict[\"wrestler_train\"]\n",
    "match_test = train_test_dict[\"match_test\"]\n",
    "wrestler_test = train_test_dict[\"wrestler_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test win percentage algorithm\n",
    "# Note: create algorithm_args dict argument for algorithms and algorithm tester\n",
    "WP_pred_results = test_algorithm(win_perc_pred,match_train,match_test,wrestler_train,wrestler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WP_pred_results['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of weight classes among wrestlers in incorrect pred cases\n",
    "# Misleading: should scale by num wrestler/matches in weight class\n",
    "# Note: make this a bar chart instead if possible\n",
    "WP_pred_results['WrongPreds'].hist(column=\"Weight Class\")\n",
    "plt.xlabel(\"Weight Class\")\n",
    "plt.ylabel(\"Number of Incorrect Predictions\")\n",
    "plt.title(\"Incorrect WP Preds by Weight Class\")\n",
    "\n",
    "# Save fig\n",
    "plt.savefig('./Plots/incorrect_preds_weight_class.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See predictive power of WP on this dataset by shrinking train data size\n",
    "train_sizes = np.linspace(start=0.5,stop=1.0,num=6)\n",
    "accuracy_dict = {}\n",
    "\n",
    "for size in train_sizes:\n",
    "    \n",
    "    train_test_dict = train_test_split(MATCHES,split_method='size',train_size=size)\n",
    "    match_train = train_test_dict[\"match_train\"]\n",
    "    wrestler_train = train_test_dict[\"wrestler_train\"]\n",
    "    match_test = train_test_dict[\"match_test\"]\n",
    "    wrestler_test = train_test_dict[\"wrestler_test\"]\n",
    "    \n",
    "    WP_pred_results = test_algorithm(win_perc_pred,match_train,match_test,wrestler_train,wrestler_test)\n",
    "    \n",
    "    accuracy_dict[size] = WP_pred_results['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.bar(range(len(accuracy_dict)), list(accuracy_dict.values()), align='center')\n",
    "plt.xticks(range(len(accuracy_dict)), list(accuracy_dict.keys()))\n",
    "plt.title('Prediction Accuracy')\n",
    "plt.xlabel('Train Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Save fig\n",
    "plt.savefig('./Plots/win_perc_pred_accuracy.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of number of matches among wrestlers\n",
    "WRESTLERS.hist(column=\"Matches\")\n",
    "plt.xlabel(\"Number of Matches\")\n",
    "plt.ylabel(\"Number of Wrestlers\")\n",
    "plt.title(\"Distribution of Wrestlers by Number of Matches\")\n",
    "\n",
    "# Save fig\n",
    "plt.savefig('./Plots/wrestler_match_dist.png')\n",
    "\n",
    "# Vast majority of wrestlers have less than 15 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of matches by weight class\n",
    "wrestlers_by_weight = WRESTLERS.groupby('Weight Class')\n",
    "wrestlers_by_weight.sum().plot.bar(y=\"Matches\")\n",
    "plt.title(\"Distribution of Matches by Weight Class\")\n",
    "\n",
    "# Save fig\n",
    "plt.savefig('./Plots/matches_by_weight_class.png')\n",
    "\n",
    "# Fairly balanced weight classes; flattened bell curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check count of matches by victory type \n",
    "# There are nan entries for Victory Type (L)\n",
    "#matches_by_wintype = MATCHES.groupby('Victory Type (L)')\n",
    "#matches_by_wintype.describe()['Match ID'].plot.bar(y='count')\n",
    "#plt.title(\"Distribution of Matches by Victory Type\")\n",
    "\n",
    "# Save fig\n",
    "#plt.savefig('./Plots/matches_by_win_type.png')\n",
    "\n",
    "# Practically all victory types are fall or decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of avg win perc by matches\n",
    "wrestlers_by_matches = WRESTLERS.groupby('Matches')\n",
    "avg_wins = wrestlers_by_matches.mean()['Wins']\n",
    "num_matches = avg_wins.index.values\n",
    "win_percs = avg_wins / num_matches\n",
    "win_percs.plot.bar()\n",
    "plt.title(\"Average Win Percentage by Number of Matches\")\n",
    "\n",
    "# Save fig\n",
    "plt.savefig('./Plots/win_percs_by_matches.png')\n",
    "\n",
    "# Does win percentage increase with number of matches?\n",
    "# More matches means more experience, but also consider that you may only get more matches if you're already winning\n",
    "# Some positive correlation, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
