{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location from which scraped data will be retrieved\n",
    "INPUT_FILE = './ScrapedMatchData/match_info_{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of files\n",
    "with open('./ScrapedMatchData/NumFiles.txt','r') as NumFile:\n",
    "    number_of_files = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of new files\n",
    "with open('./ScrapedMatchData/NumNewFiles.txt','r') as NumFile:\n",
    "    newFileNum = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all file names\n",
    "file_names = [INPUT_FILE.format(i) for i in range(1,number_of_files+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find out what each element represents\n",
    "\n",
    "# Unsure about 0th element\n",
    "# 1st element is weight class\n",
    "# 3rd/4th elements are type of victory (fall, decision, etc.)\n",
    "# 7th element is winner's score, 10th element is loser score\n",
    "# 16th thru 23rd elements are winner's and loser's names and schools\n",
    "# 31st element is round of match if tournament (quarterfinals, semifinals, etc.)\n",
    "# 40th element is numbers 1-16, or nan/none, could be tournament seed?\n",
    "# appended last entries to be event Name, event Id, dual Id, event date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all match data (takes a couple minutes)\n",
    "frames = [pd.read_json(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking order of events (should be redundant now that collecting date info)\n",
    "# for i,frame in enumerate(frames,1): # preserves order of events (scraped from newest to oldest)\n",
    "#    frame[\"Matches Passed\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one dataframe\n",
    "all_match_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating data that doesn't line up with the general format\n",
    "# Total dropped rows: 2457\n",
    "# Rows with NA in col 42 (event name): 1909 (77.7% of dropped rows)\n",
    "# # Of these, 222 have '' in col 10, seem to be weird data entries with links to actual match details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_filter = all_match_data[42] != all_match_data[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duals_only = all_match_data.loc[dual_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_drop_cols = [0,1,6,8,9,11,12,14,15,16,17,18,19,20,31,32,33,34,35,36,37,38,39,40,42,45]\n",
    "duals_only.drop(columns=dual_drop_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duals_only = duals_only.loc[duals_only[10]!=''] # drop the blank col 10 rows for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duals_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match_data.to_csv('all_match_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows do not all line up, kinda sucks\n",
    "# Look into splitting/shifting data (maybe using event names files since all blank names are duals?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original size of raw data\n",
    "all_match_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exactly duplicated rows (from webscraping process)\n",
    "# Note: Might be more duplicates that just aren't exact (from website setup), need to check further\n",
    "all_match_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Size after dropping duplicated rows\n",
    "all_match_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix below so we stop throwing away data and have representation for duals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of 15 official New York State Public High School weight classes\n",
    "\n",
    "weight_classes = {99, 106, 113, 120, 126, 132, 138, 145, 152, 160, 170, 182, 195, 220, 285}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of improper (i.e. non-integer) weight classes, the other unique values of col 1\n",
    "# alt_weight_classes = set(all_match_data[1].unique()[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, filter table to only include rows with proper weight classes\n",
    "weight_filter = [x in weight_classes for x in all_match_data[1]]\n",
    "weight_filtered_data = all_match_data.loc[weight_filter,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size after selecting only 'proper' weight classes\n",
    "weight_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns we know by inspection\n",
    "weight_filtered_data.rename(columns={1:\"Weight Class\", 3:\"Victory Type (L)\", 4:\"Victory Type (S)\",\n",
    "                         7:\"Winner Score\", 10:\"Loser Score\", 16:\"Winner First Name\",\n",
    "                         17:\"Winner Last Name\", 18:\"Winner School (L)\", 19:\"Winner School (S)\",\n",
    "                         20:\"Loser First Name\", 21:\"Loser Last Name\", 22:\"Loser School (L)\",\n",
    "                         23:\"Loser School (S)\", 29: \"Unknown (Seed?)\", 31:\"Round\", 42:\"Event Name\", 43:\"Event ID\",\n",
    "                         45:\"Event Date\"},\n",
    "                      inplace=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure weight classes and event date are cast as integers\n",
    "weight_filtered_data['Weight Class'] = [int(x) for x in weight_filtered_data['Weight Class']]\n",
    "weight_filtered_data['Event Date'] = [int(x) for x in weight_filtered_data['Event Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping empty, redundant, and/or unintelligible columns (decided by inspection)\n",
    "drop_cols = [0,2,5,6,8,9,11,12,13,14,15,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,44]\n",
    "weight_filtered_data.drop(columns=drop_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so matches now have unique IDs\n",
    "weight_filtered_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Event ID to be string instead of float\n",
    "weight_filtered_data['Event ID'] = weight_filtered_data['Event ID'].astype(str).replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean name columns \n",
    "name_cols = ['Winner First Name','Winner Last Name','Loser First Name','Loser Last Name']\n",
    "\n",
    "for name in name_cols:\n",
    "    \n",
    "    col = weight_filtered_data[name]\n",
    "    col = [x.strip().title() if type(x)==str else x for x in col] # Removes extra whitespace, ensure proper capitalization\n",
    "    weight_filtered_data[name] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full names for winners and losers from their cleaned first and last names\n",
    "weight_filtered_data['Winner Full Name'] = weight_filtered_data['Winner First Name'] + ' ' + weight_filtered_data['Winner Last Name']\n",
    "weight_filtered_data['Loser Full Name'] = weight_filtered_data['Loser First Name'] + ' ' + weight_filtered_data['Loser Last Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weight_filtered_data to csv file named MATCHES.csv\n",
    "weight_filtered_data.to_csv('MATCHES.csv') # Remember: currently only using rows with 'proper' weight classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of winner/loser full names is set of all wrestlers in dataset\n",
    "wrestlers = set(weight_filtered_data['Winner Full Name']) | set(weight_filtered_data['Loser Full Name'])\n",
    "wrestlers = [x for x in wrestlers if x==x] # remove nan, convert to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create infoscrape function that goes through dataset and collects desired info for each wrestler\n",
    "\n",
    "def infoscrape(fullname,df):\n",
    "    '''infoscrape function receives full name of wrestler and matches dataframe\n",
    "    and collects wrestler info from dataset'''\n",
    "\n",
    "    # Initialize values of interest\n",
    "    weight_class = 0\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    matches = 0\n",
    "    school = ''\n",
    "    school_code = ''\n",
    "    first_name = ''\n",
    "    last_name = ''\n",
    "    \n",
    "    # Find observations corresponding to wrestler name\n",
    "    win_id = df['Winner Full Name'] == fullname\n",
    "    loss_id = df['Loser Full Name'] == fullname\n",
    "    winning_matches = df.loc[win_id,:]\n",
    "    losing_matches = df.loc[loss_id,:]\n",
    "    \n",
    "    # Split full name\n",
    "    first_name, last_name = fullname.split(' ',1)\n",
    "    \n",
    "    # Counting stats (should check if names show in correct columns for forfeits, byes, etc.)\n",
    "    wins = sum(win_id)\n",
    "    losses = sum(loss_id)\n",
    "    matches = wins+losses\n",
    "    \n",
    "    # Extract weight class, school, etc.\n",
    "    win_weight = winning_matches['Weight Class'].unique()\n",
    "    loss_weight = losing_matches['Weight Class'].unique()\n",
    "    \n",
    "    if win_weight.size > 0: # Avoiding 'if win_weight:' because it gives truth amibiguity warning\n",
    "        weight_class = int(win_weight[0])\n",
    "    else: # !!!Still need to add consideration for multiple weight classes!!!\n",
    "        weight_class = int(loss_weight[0])\n",
    "        \n",
    "    win_school = winning_matches['Winner School (L)'].unique()\n",
    "    win_school_code = winning_matches['Winner School (S)'].unique()\n",
    "    loss_school = losing_matches['Loser School (L)'].unique()\n",
    "    loss_school_code = losing_matches['Loser School (S)'].unique()\n",
    "    \n",
    "    if win_school.size > 0: # Avoiding 'if win_school:' because it gives truth amibiguity warning\n",
    "        school = win_school[0]\n",
    "        school_code = win_school_code[0]\n",
    "    else: \n",
    "        school = loss_school[0]\n",
    "        school_code = loss_school_code[0]\n",
    "        \n",
    "    # Return list of extracted data \n",
    "    return({'First Name':first_name,'Last Name':last_name,'Full Name':fullname,\n",
    "            'School Name':school,'School Code':school_code,\n",
    "            'Weight Class':weight_class,'Wins':wins,'Losses':losses,'Matches':matches})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct wrestler dataframe (takes a minute)\n",
    "wrestler_data = [infoscrape(wrestler,weight_filtered_data) for wrestler in wrestlers]\n",
    "WRESTLERS = pd.DataFrame(wrestler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save WRESTLERS to csv file named WRESTLERS.csv\n",
    "WRESTLERS.to_csv('WRESTLERS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO\n",
    "# Remake wrestlers dataframe from cleansed matches data?\n",
    "# Once algorithm test running smoothly, do more diagnostics\n",
    "### Look for patterns in incorrect preds\n",
    "### Pick high risk subsets of wrestlers (like in meeting notes) and see how algorithm performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
