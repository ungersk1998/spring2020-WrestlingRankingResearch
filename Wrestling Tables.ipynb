{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location from which scraped data will be retrieved\n",
    "INPUT_FILE = './ScrapedMatchData/match_info_{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of files\n",
    "with open('./ScrapedMatchData/NumFiles.txt','r') as NumFile:\n",
    "    number_of_files = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of new files\n",
    "with open('./ScrapedMatchData/NumNewFiles.txt','r') as NumFile:\n",
    "    newFileNum = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all file names\n",
    "file_names = [INPUT_FILE.format(i) for i in range(1,number_of_files+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find out what each element represents\n",
    "\n",
    "# Unsure about 0th element\n",
    "# 1st element is weight class\n",
    "# 3rd/4th elements are type of victory (fall, decision, etc.)\n",
    "# 7th element is winner's score, 10th element is loser score\n",
    "# 16th thru 23rd elements are winner's and loser's names and schools\n",
    "# 31st element is round of match if tournament (quarterfinals, semifinals, etc.)\n",
    "# 40th element is numbers 1-16, or nan/none, could be tournament seed?\n",
    "# appended last entries to be event Name, event Id, dual Id, event date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all match data (takes a couple minutes)\n",
    "frames = [pd.read_json(file_name) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking order of events (should be redundant now that collecting date info)\n",
    "for i,frame in enumerate(frames,1): # preserves order of events (scraped from newest to oldest)\n",
    "    frame[\"Matches Passed\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one dataframe\n",
    "all_match_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match_data.to_csv('all_match_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows do not all line up, kinda sucks\n",
    "# Look into splitting/shifting data (maybe using event names files since all blank names are duals?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20819, 47)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original size of raw data\n",
    "all_match_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20819, 47)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop exactly duplicated rows (from webscraping process)\n",
    "# Note: Might be more duplicates that just aren't exact (from website setup), need to check further\n",
    "all_match_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Size after dropping duplicated rows\n",
    "all_match_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix below so we stop throwing away data and have representation for duals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of 15 official New York State Public High School weight classes\n",
    "\n",
    "weight_classes = {99, 106, 113, 120, 126, 132, 138, 145, 152, 160, 170, 182, 195, 220, 285}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of improper (i.e. non-integer) weight classes, the other unique values of col 1\n",
    "# alt_weight_classes = set(all_match_data[1].unique()[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, filter table to only include rows with proper weight classes\n",
    "weight_filter = [x in weight_classes for x in all_match_data[1]]\n",
    "weight_filtered_data = all_match_data.loc[weight_filter,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18362, 47)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data size after selecting only 'proper' weight classes\n",
    "weight_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\pandas\\core\\frame.py:4130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Rename columns we know by inspection\n",
    "weight_filtered_data.rename(columns={1:\"Weight Class\", 3:\"Victory Type (L)\", 4:\"Victory Type (S)\",\n",
    "                         7:\"Winner Score\", 10:\"Loser Score\", 16:\"Winner First Name\",\n",
    "                         17:\"Winner Last Name\", 18:\"Winner School (L)\", 19:\"Winner School (S)\",\n",
    "                         20:\"Loser First Name\", 21:\"Loser Last Name\", 22:\"Loser School (L)\",\n",
    "                         23:\"Loser School (S)\", 29: \"Unknown (Seed?)\", 31:\"Round\", 42:\"Event Name\", 43:\"Event ID\",\n",
    "                         45:\"Event Date\"},\n",
    "                      inplace=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Ensure weight classes and event date are cast as integers\n",
    "weight_filtered_data['Weight Class'] = [int(x) for x in weight_filtered_data['Weight Class']]\n",
    "weight_filtered_data['Event Date'] = [int(x) for x in weight_filtered_data['Event Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\pandas\\core\\frame.py:3994: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Dropping empty, redundant, and/or unintelligible columns (decided by inspection)\n",
    "drop_cols = [0,2,5,6,8,9,11,12,13,14,15,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,44]\n",
    "weight_filtered_data.drop(columns=drop_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so matches now have unique IDs\n",
    "weight_filtered_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Fix Event ID to be string instead of float\n",
    "weight_filtered_data['Event ID'] = weight_filtered_data['Event ID'].astype(str).replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### Clean name columns \n",
    "name_cols = ['Winner First Name','Winner Last Name','Loser First Name','Loser Last Name']\n",
    "\n",
    "for name in name_cols:\n",
    "    \n",
    "    col = weight_filtered_data[name]\n",
    "    col = [x.strip().title() if type(x)==str else x for x in col] # Removes extra whitespace, ensure proper capitalization\n",
    "    weight_filtered_data[name] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\colum\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create full names for winners and losers from their cleaned first and last names\n",
    "weight_filtered_data['Winner Full Name'] = weight_filtered_data['Winner First Name'] + ' ' + weight_filtered_data['Winner Last Name']\n",
    "weight_filtered_data['Loser Full Name'] = weight_filtered_data['Loser First Name'] + ' ' + weight_filtered_data['Loser Last Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weight_filtered_data to csv file named MATCHES.csv\n",
    "weight_filtered_data.to_csv('MATCHES.csv') # Remember: currently only using rows with 'proper' weight classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of winner/loser full names is set of all wrestlers in dataset\n",
    "wrestlers = set(weight_filtered_data['Winner Full Name']) | set(weight_filtered_data['Loser Full Name'])\n",
    "wrestlers = [x for x in wrestlers if x==x] # remove nan, convert to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create infoscrape function that goes through dataset and collects desired info for each wrestler\n",
    "\n",
    "def infoscrape(fullname,df):\n",
    "    '''infoscrape function receives full name of wrestler and matches dataframe\n",
    "    and collects wrestler info from dataset'''\n",
    "\n",
    "    # Initialize values of interest\n",
    "    weight_class = 0\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    matches = 0\n",
    "    school = ''\n",
    "    school_code = ''\n",
    "    first_name = ''\n",
    "    last_name = ''\n",
    "    \n",
    "    # Find observations corresponding to wrestler name\n",
    "    win_id = df['Winner Full Name'] == fullname\n",
    "    loss_id = df['Loser Full Name'] == fullname\n",
    "    winning_matches = df.loc[win_id,:]\n",
    "    losing_matches = df.loc[loss_id,:]\n",
    "    \n",
    "    # Split full name\n",
    "    first_name, last_name = fullname.split(' ',1)\n",
    "    \n",
    "    # Counting stats (should check if names show in correct columns for forfeits, byes, etc.)\n",
    "    wins = sum(win_id)\n",
    "    losses = sum(loss_id)\n",
    "    matches = wins+losses\n",
    "    \n",
    "    # Extract weight class, school, etc.\n",
    "    win_weight = winning_matches['Weight Class'].unique()\n",
    "    loss_weight = losing_matches['Weight Class'].unique()\n",
    "    \n",
    "    if win_weight.size > 0: # Avoiding 'if win_weight:' because it gives truth amibiguity warning\n",
    "        weight_class = int(win_weight[0])\n",
    "    else: # !!!Still need to add consideration for multiple weight classes!!!\n",
    "        weight_class = int(loss_weight[0])\n",
    "        \n",
    "    win_school = winning_matches['Winner School (L)'].unique()\n",
    "    win_school_code = winning_matches['Winner School (S)'].unique()\n",
    "    loss_school = losing_matches['Loser School (L)'].unique()\n",
    "    loss_school_code = losing_matches['Loser School (S)'].unique()\n",
    "    \n",
    "    if win_school.size > 0: # Avoiding 'if win_school:' because it gives truth amibiguity warning\n",
    "        school = win_school[0]\n",
    "        school_code = win_school_code[0]\n",
    "    else: \n",
    "        school = loss_school[0]\n",
    "        school_code = loss_school_code[0]\n",
    "        \n",
    "    # Return list of extracted data \n",
    "    return({'First Name':first_name,'Last Name':last_name,'Full Name':fullname,\n",
    "            'School Name':school,'School Code':school_code,\n",
    "            'Weight Class':weight_class,'Wins':wins,'Losses':losses,'Matches':matches})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct wrestler dataframe (takes a minute)\n",
    "wrestler_data = [infoscrape(wrestler,weight_filtered_data) for wrestler in wrestlers]\n",
    "WRESTLERS = pd.DataFrame(wrestler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save WRESTLERS to csv file named WRESTLERS.csv\n",
    "WRESTLERS.to_csv('WRESTLERS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
