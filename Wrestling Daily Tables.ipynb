{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of new files\n",
    "with open('./ScrapedMatchData/NumNewFiles.txt','r') as NumFile:\n",
    "    newFileNum = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to update tables if no new files!!!\n",
    "# This \"run if new files\" logic can probably go into the bash (batch?) file\n",
    "# to decide whether to run this notebook --> doesn't have to be in the notebook itself\n",
    "\n",
    "## %%javascript\n",
    "## if (newFileNum==0){\n",
    "##    Jupyter.notebook.session.delete();\n",
    "## }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in already made matches and wrestlers dataframes, label IDs\n",
    "MATCHES = pd.read_csv('MATCHES.csv').rename(columns={'Unnamed: 0':'Match ID'})\n",
    "WRESTLERS = pd.read_csv('WRESTLERS.csv').rename(columns={'Unnamed: 0':'Wrestler ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location from which scraped data will be retrieved\n",
    "INPUT_FILE = './ScrapedMatchData/match_info_{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve number of files\n",
    "with open('./ScrapedMatchData/NumFiles.txt','r') as NumFile:\n",
    "    number_of_files = int(NumFile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting index for new data\n",
    "newCutoff = number_of_files - newFileNum + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all new file names\n",
    "new_file_names = [INPUT_FILE.format(i) for i in range(newCutoff,number_of_files+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new match data\n",
    "frames = [pd.read_json(file_name) for file_name in new_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking order of events (should be redundant now that collecting date info)\n",
    "for i,frame in enumerate(frames,newCutoff): # starts from first new file\n",
    "    frame[\"Matches Passed\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b7df0a7d424f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Combine new match data into one dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_match_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\webscraping\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Combine new match data into one dataframe\n",
    "new_match_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exactly duplicated rows (from webscraping process)\n",
    "# Note: Might be more duplicates that just aren't exact (from website setup), need to check further\n",
    "all_match_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Size after dropping duplicated rows\n",
    "all_match_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix below so we stop throwing away data and have representation for duals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of 15 official New York State Public High School weight classes\n",
    "\n",
    "weight_classes = {99, 106, 113, 120, 126, 132, 138, 145, 152, 160, 170, 182, 195, 220, 285}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define set of improper (i.e. non-integer) weight classes, the other unique values of col 1\n",
    "# alt_weight_classes = set(all_match_data[1].unique()[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, filter table to only include rows with proper weight classes\n",
    "weight_filter = [x in weight_classes for x in all_match_data[1]]\n",
    "weight_filtered_data = all_match_data.loc[weight_filter,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size after selecting only 'proper' weight classes\n",
    "weight_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns we know by inspection\n",
    "weight_filtered_data.rename(columns={1:\"Weight Class\", 3:\"Victory Type (L)\", 4:\"Victory Type (S)\",\n",
    "                         7:\"Winner Score\", 10:\"Loser Score\", 16:\"Winner First Name\",\n",
    "                         17:\"Winner Last Name\", 18:\"Winner School (L)\", 19:\"Winner School (S)\",\n",
    "                         20:\"Loser First Name\", 21:\"Loser Last Name\", 22:\"Loser School (L)\",\n",
    "                         23:\"Loser School (S)\", 29: \"Unknown (Seed?)\", 31:\"Round\", 42:\"Event Name\", 43:\"Event ID\",\n",
    "                         45:\"Event Date\"},\n",
    "                      inplace=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure weight classes and event date are cast as integers\n",
    "weight_filtered_data['Weight Class'] = [int(x) for x in weight_filtered_data['Weight Class']]\n",
    "weight_filtered_data['Event Date'] = [int(x) for x in weight_filtered_data['Event Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping empty, redundant, and/or unintelligible columns (decided by inspection)\n",
    "drop_cols = [0,2,5,6,8,9,11,12,13,14,15,24,25,26,27,28,30,32,33,34,35,36,37,38,39,40,41,44]\n",
    "weight_filtered_data.drop(columns=drop_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index so matches now have unique IDs\n",
    "weight_filtered_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Event ID to be string instead of float\n",
    "weight_filtered_data['Event ID'] = weight_filtered_data['Event ID'].astype(str).replace('\\.0', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean name columns \n",
    "name_cols = ['Winner First Name','Winner Last Name','Loser First Name','Loser Last Name']\n",
    "\n",
    "for name in name_cols:\n",
    "    \n",
    "    col = weight_filtered_data[name]\n",
    "    col = [x.strip().title() if type(x)==str else x for x in col] # Removes extra whitespace, ensure proper capitalization\n",
    "    weight_filtered_data[name] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full names for winners and losers from their cleaned first and last names\n",
    "weight_filtered_data['Winner Full Name'] = weight_filtered_data['Winner First Name'] + ' ' + weight_filtered_data['Winner Last Name']\n",
    "weight_filtered_data['Loser Full Name'] = weight_filtered_data['Loser First Name'] + ' ' + weight_filtered_data['Loser Last Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weight_filtered_data to csv file named MATCHES.csv\n",
    "weight_filtered_data.to_csv('MATCHES.csv') # Remember: currently only using rows with 'proper' weight classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of winner/loser full names is set of all wrestlers in dataset\n",
    "wrestlers = set(weight_filtered_data['Winner Full Name']) | set(weight_filtered_data['Loser Full Name'])\n",
    "wrestlers = [x for x in wrestlers if x==x] # remove nan, convert to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create infoscrape function that goes through dataset and collects desired info for each wrestler\n",
    "\n",
    "def infoscrape(fullname,df):\n",
    "    '''infoscrape function receives full name of wrestler and matches dataframe\n",
    "    and collects wrestler info from dataset'''\n",
    "\n",
    "    # Initialize values of interest\n",
    "    weight_class = 0\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    matches = 0\n",
    "    school = ''\n",
    "    school_code = ''\n",
    "    first_name = ''\n",
    "    last_name = ''\n",
    "    \n",
    "    # Find observations corresponding to wrestler name\n",
    "    win_id = df['Winner Full Name'] == fullname\n",
    "    loss_id = df['Loser Full Name'] == fullname\n",
    "    winning_matches = df.loc[win_id,:]\n",
    "    losing_matches = df.loc[loss_id,:]\n",
    "    \n",
    "    # Split full name\n",
    "    first_name, last_name = fullname.split(' ',1)\n",
    "    \n",
    "    # Counting stats (should check if names show in correct columns for forfeits, byes, etc.)\n",
    "    wins = sum(win_id)\n",
    "    losses = sum(loss_id)\n",
    "    matches = wins+losses\n",
    "    \n",
    "    # Extract weight class, school, etc.\n",
    "    win_weight = winning_matches['Weight Class'].unique()\n",
    "    loss_weight = losing_matches['Weight Class'].unique()\n",
    "    \n",
    "    if win_weight.size > 0: # Avoiding 'if win_weight:' because it gives truth amibiguity warning\n",
    "        weight_class = int(win_weight[0])\n",
    "    else: # !!!Still need to add consideration for multiple weight classes!!!\n",
    "        weight_class = int(loss_weight[0])\n",
    "        \n",
    "    win_school = winning_matches['Winner School (L)'].unique()\n",
    "    win_school_code = winning_matches['Winner School (S)'].unique()\n",
    "    loss_school = losing_matches['Loser School (L)'].unique()\n",
    "    loss_school_code = losing_matches['Loser School (S)'].unique()\n",
    "    \n",
    "    if win_school.size > 0: # Avoiding 'if win_school:' because it gives truth amibiguity warning\n",
    "        school = win_school[0]\n",
    "        school_code = win_school_code[0]\n",
    "    else: \n",
    "        school = loss_school[0]\n",
    "        school_code = loss_school_code[0]\n",
    "        \n",
    "    # Return list of extracted data \n",
    "    return({'First Name':first_name,'Last Name':last_name,'Full Name':fullname,\n",
    "            'School Name':school,'School Code':school_code,\n",
    "            'Weight Class':weight_class,'Wins':wins,'Losses':losses,'Matches':matches})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct wrestler dataframe (takes a minute)\n",
    "wrestler_data = [infoscrape(wrestler,weight_filtered_data) for wrestler in wrestlers]\n",
    "WRESTLERS = pd.DataFrame(wrestler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save WRESTLERS to csv file named WRESTLERS.csv\n",
    "WRESTLERS.to_csv('WRESTLERS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
