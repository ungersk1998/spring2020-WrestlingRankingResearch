{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from random import uniform\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRESTLING_URL = 'https://www.trackwrestling.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aiming to place scraped data in its own folder\n",
    "OUTPUT_FILE = './ScrapedMatchData/match_info_{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notes:\n",
    "# Events page caps at 250 events, which is roughly the last week. Can't keep scrolling like the indeed page number code\n",
    "# Maybe need to send specific search params by date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remote browsing through selenium\n",
    "### MAKE SURE TO USE SLEEP SO YOU DON'T GET BLOCKED!!!\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(1.5) # force wait time (need to check documentation)\n",
    "driver.get(WRESTLING_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Following cells navigate from trackwrestling landing page to New York State events pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"displayMenu('subMenu-browse', 'left', 1, 'Browse')\")\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"displayMenu('subMenu-seasons', 'left', 2, 'Seasons')\")\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"displayMenu('subMenu-seasonOrganizeBy_1428400132', 'left', 3, '2019-20 High School Boys')\")\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"gotoBuildURLPage('seasons/LoadBalance.jsp?seasonId=1428400132&gbId=38&uname=&pword=')\")\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save cookies\n",
    "pickle.dump(driver.get_cookies(), open(\"cookies.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add cookies for page access\n",
    "cookies = pickle.load(open(\"cookies.pkl\", \"rb\"))\n",
    "for cookie in cookies:\n",
    "    driver.add_cookie(cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scrapes info of each match for every event/dual in the last 250 entries to trackwrestling\n",
    "\n",
    "# Can probably take regex compile statements out of loop for efficiency\n",
    "# Look into adding more wait time when opening dual window\n",
    "# Play with length of sleeps, try to minimize\n",
    "# Current runtime: ~40 minutes\n",
    "\n",
    "match_Id = 0\n",
    "events_url = driver.current_url\n",
    "default_window = driver.window_handles[0]\n",
    "\n",
    "driver.switch_to.frame('PageFrame')\n",
    "\n",
    "# Show all 250 entries for easier scraping\n",
    "max_value = driver.find_element_by_xpath(\"//input[@value='50']\") # searches based on default value\n",
    "max_value.send_keys(Keys.CONTROL,'a')\n",
    "max_value.send_keys('250')\n",
    "max_value.send_keys(Keys.ENTER)\n",
    "\n",
    "for i in range(0,250): # check all 250 events on page\n",
    "    \n",
    "    # openEvent either opens the match results in new window or asks user to pick a specific team\n",
    "    driver.execute_script(\"openEvent({})\".format(i))\n",
    "    sleep(uniform(0.5,0.7))\n",
    "    \n",
    "    if len(driver.window_handles) == 1: # user prompted; need to loop through various teams\n",
    "        \n",
    "        frame_html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "        frame_soup = BeautifulSoup(frame_html,'html.parser')\n",
    "        \n",
    "        all_links = [str(link.get('href')) for link in frame_soup.find_all('a')]\n",
    "        max_link_length = max(map(len,all_links)) # the links we want will always be the longest in the page\n",
    "        team_links = [link for link in all_links if len(link)==max_link_length]\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        \n",
    "        for link in team_links: \n",
    "                        \n",
    "            driver.get(WRESTLING_URL+'/seasons/'+link)\n",
    "            sleep(uniform(0.5,0.7))\n",
    "            \n",
    "            match_html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "            \n",
    "            # compile regex for elements we want to find\n",
    "            initDataGrid_regex = re.compile(r'initDataGrid\\(1000, false, \\\"(.*\\]\\])')\n",
    "            eventName_regex = re.compile(r'drawPageHeader\\(\\\"(.*)\\\"\\)')\n",
    "            eventId_regex = re.compile(r'eventId=(.*)&')\n",
    "            teamId_regex = re.compile(r'teamId=(.*)')\n",
    "\n",
    "            eventName = eventName_regex.findall(match_html)\n",
    "                \n",
    "            if not eventName: # error page, back out and hope for the best\n",
    "                \n",
    "                driver.execute_script(\"window.history.go(-1)\")\n",
    "                sleep(uniform(0.5,0.7))\n",
    "                default_window = driver.window_handles[0]\n",
    "                sleep(uniform(0.5,0.7))\n",
    "                driver.switch_to.frame('PageFrame')\n",
    "                \n",
    "            else: # real page, all good\n",
    "                \n",
    "                eventName = eventName[0].strip()\n",
    "                teamId = teamId_regex.findall(link)[0]\n",
    "                eventId = eventId_regex.findall(link)[0]\n",
    "                dualId = None\n",
    "            \n",
    "                match_data = initDataGrid_regex.findall(match_html)\n",
    "                \n",
    "                if match_data: # empty record check\n",
    "                \n",
    "                    # remove control chars that make json.loads unhappy\n",
    "                    match_data = match_data[0]\n",
    "                    match_data = re.sub(r'\\\\','',match_data)\n",
    "                    match_data = re.sub(r'\\t','',match_data)\n",
    "                    match_data = re.sub(r'\\n','',match_data)\n",
    "                    match_data = re.sub(r'\\r','',match_data)\n",
    "                    match_data_list = json.loads(match_data)\n",
    "\n",
    "                    # note order of appended items\n",
    "                    for each_match in match_data_list:\n",
    "\n",
    "                        each_match.append(eventName)\n",
    "                        each_match.append(eventId)\n",
    "                        each_match.append(dualId)\n",
    "\n",
    "                    match_Id += 1\n",
    "\n",
    "                    json.dump(match_data_list,\n",
    "                             open(OUTPUT_FILE.format(match_Id),'w'))\n",
    "        \n",
    "        # return to events page ready to open next event\n",
    "        driver.get(events_url)\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        default_window = driver.window_handles[0]\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        driver.switch_to.frame('PageFrame')\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        \n",
    "        # Show all 250 entries for easier scraping\n",
    "        max_value = driver.find_element_by_xpath(\"//input[@value='50']\")\n",
    "        max_value.send_keys(Keys.CONTROL,'a')\n",
    "        max_value.send_keys('250')\n",
    "        max_value.send_keys(Keys.ENTER)\n",
    "\n",
    "    else: # match info opened in new window\n",
    "        \n",
    "        driver.switch_to.window(default_window)\n",
    "        driver.switch_to.default_content\n",
    "        \n",
    "        match_window = driver.window_handles[1] # remember new window\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        \n",
    "        driver.switch_to.window(match_window) # switch to new window\n",
    "        sleep(uniform(0.5,0.7))\n",
    "            \n",
    "        match_html = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "        link = driver.current_url\n",
    "        \n",
    "        # compile regex (note that these are just two-team duals, not multi-team events)\n",
    "        initDataGrid_regex = re.compile(r'initDataGrid\\(1000, false, \\\"(.*\\]\\])')\n",
    "        eventName_regex = re.compile(r'drawPageHeader\\(\\\"(.*)\\(')\n",
    "        dualId_regex = re.compile(r'dualId=(.*)&')\n",
    "        teamId_regex = re.compile(r'teamId=(.*)')\n",
    "\n",
    "        eventName = eventName_regex.findall(match_html)\n",
    "        \n",
    "        if eventName: # real page, all good\n",
    "                \n",
    "            eventName = eventName[0].strip()\n",
    "            teamId = teamId_regex.findall(link)[0]\n",
    "            dualId = dualId_regex.findall(link)[0]\n",
    "            eventId = None\n",
    "            \n",
    "            match_data = initDataGrid_regex.findall(match_html)\n",
    "                \n",
    "            if match_data: # empty record check\n",
    "                \n",
    "                # remove control chars that make json.loads unhappy\n",
    "                match_data = match_data[0]\n",
    "                match_data = re.sub(r'\\\\','',match_data)\n",
    "                match_data = re.sub(r'\\t','',match_data)\n",
    "                match_data = re.sub(r'\\n','',match_data)\n",
    "                match_data = re.sub(r'\\r','',match_data)\n",
    "                match_data_list = json.loads(match_data)\n",
    "\n",
    "                # note order of appended items\n",
    "                for each_match in match_data_list:\n",
    "\n",
    "                    each_match.append(eventName)\n",
    "                    each_match.append(eventId)\n",
    "                    each_match.append(dualId)\n",
    "\n",
    "                match_Id += 1\n",
    "\n",
    "                json.dump(match_data_list,\n",
    "                            open(OUTPUT_FILE.format(match_Id),'w'))\n",
    "                \n",
    "        # closes new window and returns to events page to open next event\n",
    "        driver.close()\n",
    "        driver.switch_to.window(default_window)\n",
    "        sleep(uniform(0.5,0.7))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save number of individual JSON files for later use\n",
    "\n",
    "with open('./ScrapedMatchData/NumFiles.txt','w') as NumFile:\n",
    "    NumFile.write(str(match_Id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
