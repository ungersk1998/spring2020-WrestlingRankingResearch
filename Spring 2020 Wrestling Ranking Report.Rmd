---
title: "Spring 2020 Wrestling Ranking Report"
author: "Sam Unger"
date: "May 7, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Introduction

In high school wrestling, manual ranking processes are commonplace and waste an excessive amount of time and
effort that could be saved using some sort of automated ranking system. Anecdotal evidence suggests that, on
average, ??? hours/minutes are spent at each wrestling meet manually ranking the competing wrestlers before
any bouts can even begin. This is time that could otherwise belong to the coaches, wrestlers, and families
involved with the sport if a reliable automated ranking system were utilized. Thus, there exists much
potential value in developing ranking algorithms for use on high school wrestling data, especially when
implementing those algorithms in a user-friendly format easily deployable by coaches and wrestlers. Additional
requirements for such ranking algorithms include easily updatable rankings as well as a sensible cold-start
ranking methodology for wrestlers without previous matches. To satisfy these requirements, we follow
suggestions from previous wrestling ranking literature and develop an Elo rating system to rank the wrestlers
in our dataset, testing our rankings by predicting the winners of already completed matches and comparing
those predictions to the true winners of those matches. 

## Literature Review

We consulted a research article titled ["Ranking and Prediction of Collegiate Wrestling"](https://content.iospress.com/articles/journal-of-sports-analytics/jsa0024)
written by University of Iowa affiliates Kristina Gavin Bigsby and Jeffrey W. Ohlmann and published in April
2017 in the Journal of Sports Analytics. In this paper, Bigsby and Ohlmann investigate various collegiate
wrestling ranking methods, including win percentage and Elo ratings, using data from the 2013-2014 NCAA
Division I wrestling season. Their analysis suggests that "Elo presents an especially attractive alternative
to current ranking systems for college wrestling." Building off Bigsby and Ohlmann's promising results, we
implement an Elo rating method on our high school wrestling data to investigate the algorithm's efficacy at
the lower competitive level. 

## Material and Methods

### Dataset

For this project, we scraped [trackwrestling.com](http://trackwrestling.com) for recent data from the
2019-2020 High School Boys Wrestling season of the New York State Public High School Athletic Association. See
our code on [GitHub](https://github.com/ungersk1998/spring2020-WrestlingRankingResearch) for full details on
the webscraping and data preparation used in this project. From our raw data, we filtered out matches with
non-competitive victory types, such as forfeit, injury, disqualification, and bye. This resulted in a final
dataset that includes 6630 individual wrestling matches, each containing names of the winning and losing
wrestlers as well as their weight class and schools, along with information on the event name and date and the
points awarded to the wrestlers during the match. 3868 unique wrestlers make up the competitors in these 6630
matches. One very important note regarding this data is that it does not contain a full season of matches; due
to complications with scraping data from [trackwrestling.com](http://trackwrestling.com), our earliest records
are only from late January 2020, well into the New York State high school wrestling season. As such, we
believe that all of our results, although already promising, could be much better realized in the future, when
we can track a season fully from its start to have more ideal data. 

- EDA plots for data
- General Comments

### Algorithms

The primary prediction algorithms we test in this project are win percentage and Elo. Our win percentage
predictor serves as our baseline for comparison, given that it simply predicts the winner of a match to be the
wrestler with the higher win percentage over the current season. In our implementation, cold-start issues are
resolved by assigning to new wrestlers (i.e. 0 matches competed) the average win percentage of their school's
wrestlers, operating under the assumption that a team of wrestlers should have relatively similar skill levels.
In cases where a new wrestler does not have any teammate data with which to impute, we assign them the average
win percentage of wrestlers who competed in a similar number of matches, assuming experience to correlate
positively with skill.

As for the Elo algorithm, it is a computationally simple, yet highly flexible method. Elo treats prior ratings
as an indicator of wrestler strength, using the difference in ratings between competitors at the time of a
match to compute an expected probability of victory. Ratings after the match are adjusted based upon the
disparity between this expected result and the actual result, with more rating points earned for an upset than
a predictable win. We implement Elo rating in Python via the [Elote](https://pypi.org/project/elote/) package
by Will McGinnis. We take our parameter values for the Elo algorithm from the Bigsby and Ohlmann research
article, which suggests an initial rating of 1000 for each wrestler and a $K$ value, which determines the
ratings' sensitivity to a new match, of 225. While the initial rating parameter typically increases with the
size of the dataset, it has no effect on predictive accuracy. Meanwhile, the $K$ value typically has the
strongest effect on predictive accuracy, and therefore its value should be carefully selected through
precedent or cross-validation. The steps of the Elo algorithm, as implemented in the
[Elote](https://pypi.org/project/elote/) package by McGinnis, are the following (equations are written with
the opponent being the true loser of the match):

1. Transformed Current Rating: $R'=10^{R/R_{init}}$

$R$ is a wrestler's rating before the match, and $R_{init}$ is their initial rating.

2. Expected Result: $S_{exp}=\frac{R'}{R'+R'_{opp}}$

$S_{exp}$ can be interpreted as the probability of winning plus half the probability of drawing. The $opp$ subscript denotes a variable corresponding to the wrestler's opponent.

3. Update Rating (Winner): $R=R+K(1-S_{exp})$

4. Update Rating (Loser): $R_{opp}=R_{opp}+K(0-S^{exp}_{opp})$

$K$ is the aforementioned $K$ value; one can see its control over rating sensitivity via its
multiplicative nature in the update rating equations. Here we work through the Elo algorithm on an example
match to demonstrate its simplicity and utility for competitive rankings. Let our wrestlers be Wrestler A and
Wrestler B.

- Wrestler A has a rating of $R_A=500$ before the match
- Wrestler B has a rating of $R_B=400$ before the match
- $R_{init}=400$ and $K=32$

First, we calculate the wrestlers' transformed ratings, $R'_A$ and $R'_B$:

1. $R'=10^{R/R_{init}} \implies R'_A=17.78 \ , \ R'_B=10.00$

Wrestler A has a higher raw rating than Wrestler B, so it makes sense that their transformed rating does as
well. Next, we calculate the expected result:

2. $S_{exp}=\frac{R'}{R'+R'_{opp}} \implies S_{exp}=0.64$

Recall, $S_{exp}$ can be interpreted as the probability of winning plus half the probability of drawing. Thus,
we reasonably expect Wrestler A, with their higher pre-match rating, to be more likely to win the match.

At this point, the actual result of the match will determine how the ratings are updated. If Wrestler A wins
(as expected), they will take some points from Wrestler B:

3. $R=R+K(1-S_{exp}) \implies R_A=511.52$

4. $R_{opp}=R_{opp}+K(0-S^{exp}_{opp}) \implies R_B=388.48$

However, more points are exchanged if there is an upset. If Wrestler B wins despite his lower rating, they
will be rewarded for beating a tough opponent -- and Wrestler A will be equivalently punished for losing a
match they were expected to win:

3. $R=R+K(1-S_{exp}) \implies R_B=420.48$

4. $R_{opp}=R_{opp}+K(0-S^{exp}_{opp}) \implies R_A=479.52$

Note that even when Wrestler B upsets Wrestler A, he still has a lower rating after the match. If we wanted
the ratings to be more sensitive, increasing $K$ would increase how many points are exchanged as a result of
the match. 

As described and demonstrated above, one can see how the Elo algorithm's built-in control over sensitivity,
ratings, and prediction make it a very promising technique for use in competitive wrestling. 

### Evaluation

To test our Win Percentage and Elo algorithms, we divided our filtered dataset into train and test sets of
various sizes, with train sets including between 50% and 90% of the total matches. The train and test sets
were split temporally so that our testing process better reflects the real-world process of predicting
matchups by past match data. Once train and test sets are created, we train our algorithms on the train sets
then accept info from the test set matches, such as wrestler and school names, to form our predictions for the
winners of the test set matches. Algorithms were judged on their predictive accuracy, as calculated by number
of correctly predicted winners divided by number of matches in the test set.

## Results and Follow-Up Analysis

Here are the prediction accuracy results of the Win Percentage algorithm for various train set sizes:

![](/~/Plots/WinPerc/win_perc_pred_accuracy.png)

With the mid-range train set sizes near 50%, we see the Win Percentage algorithm correctly predict roughly 55%
of test set matches, barely better than randomly guessing the winner of a one-on-one wrestling match. However,
we see significant improvement on the algorithm's predictive performance, climbing to 84% prediction accuracy,
once the train set contains more than 70% of the available matches. This result is somewhat surprising to us,
since we did not expect win percentage, being such a naive predictor, to perform as well as the 80% accuracy
range at any test set size.

Now, for comparison, here are the prediction accuracy results of the Elo algorithm for various train set
sizes:

![](/~/Plots/Elo/elo_pred_accuracy.png)

Notably, Elo demonstrates much worse performance than Win Percentage at smaller train set sizes. In fact, with
prediction accuracy barely surpassing 30%, using Elo is theoretically worse than randomly guessing match
winners. However, at larger train set sizes, the accuracy of the Elo algorithm improves dramatically, even
moreso than the Win Percentage algorithm, reaching a peak prediction accuracy of approximately 86%. While this
appears to be only a slight improvement from the Win Percentage algorithm, it agrees with the results found in
Bigsby and Ohlmann's wrestling ranking paper, signaling that Elo consistently (albeit not drastically)
outperforms Win Percentage as a predictor of wrestling matches.

- Acccuracy: Elo vs WP
- Certainty: Elo vs WP
- Predictive Accuracy (how good for how long)
- Special cases (few matches, cold starts, follow specific player, etc.)

## Discussion/Conclusion

- Elo vs WP
- Document difficulties
- Future work on code itself
- Future work in field
