---
title: "Spring 2020 Wrestling Ranking Report"
author: "Sam Unger"
date: "May 7, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction

In high school wrestling, manual ranking processes are commonplace and waste an excessive amount of time and
effort that could be saved using some sort of automated ranking system. Anecdotal evidence suggests that, on
average, ??? hours/minutes are spent at each wrestling meet manually ranking the competing wrestlers before any
bouts can even begin. This is time that could otherwise belong to the coaches, wrestlers, and families involved
with the sport if a reliable automated ranking system were utilized. Thus, there exists much potential value in
developing ranking algorithms for use on high school wrestling data, especially when implementing those
algorithms in a user-friendly format easily deployable by coaches and wrestlers. Additional requirements for
such ranking algorithms include easily updatable rankings as well as a sensible cold-start ranking methodology
for wrestlers without previous matches. To satisfy these requirements, we follow suggestions from previous
wrestling ranking literature and develop an Elo rating system to rank the wrestlers in our dataset, testing our
rankings by predicting the winners of already completed matches and comparing those predictions to the true winners of those matches. 

## Literature Review

We consulted a research article titled ["Ranking and Prediction of Collegiate Wrestling"](https://content.iospress.com/articles/journal-of-sports-analytics/jsa0024)
written by University of Iowa affiliates Kristina Gavin Bigsby and Jeffrey W. Ohlmann and published in April
2017 in the Journal of Sports Analytics. In this paper, Bigsby and Ohlmann investigate various collegiate
wrestling ranking methods, including win percentage and Elo ratings, using data from the 2013-2014 NCAA
Division I wrestling season. Their analysis suggests that "Elo presents an especially attractive alternative to
current ranking systems for college wrestling." Building off Bigsby and Ohlmann's promising results, we
implement an Elo rating method on our high school wrestling data to investigate the algorithm's efficacy at the
lower competitive level. 

## Material and Methods

### Dataset

For this project, we scraped [trackwrestling.com](http://trackwrestling.com) for recent data from the 2019-2020
High School Boys Wrestling season of the New York State Public High School Athletic Association. See our code
on [GitHub](https://github.com/ungersk1998/spring2020-WrestlingRankingResearch) for full details on the
webscraping and data preparation used in this project. From our raw data, we filtered out matches with
non-competitive victory types, such as forfeit, injury, disqualification, and bye. This resulted in a final
dataset that includes 6630 individual wrestling matches, each containing names of the winning and losing
wrestlers as well as their weight class and schools, along with information on the event name and date and the
points awarded to the wrestlers during the match. 3868 unique wrestlers make up the competitors in these 6630
matches. One very important note regarding this data is that it does not contain a full season of matches; due
to complications with scraping data from [trackwrestling.com](http://trackwrestling.com), our earliest records
are only from late January 2020, well into the New York State high school wrestling season. As such, we believe
that all of our results, although already promising, could be much better realized in the future, when we can
track a season fully from its start to have more ideal data. 

- EDA plots for data
- General Comments

### Algorithms

The primary prediction algorithms we test in this project are win percentage and Elo. Our win percentage
predictor serves as our baseline for comparison, given that it simply predicts the winner of a match to be the
wrestler with the higher win percentage over the current season. In our implementation, cold-start issues are
resolved by assigning to new wrestlers (i.e. 0 matches competed) the average win percentage of their school's
wrestlers, operating under the assumption that a team of wrestlers should have relatively similar skill levels.
In cases where a new wrestler does not have any teammate data with which to impute, we assign them the average
win percentage of wrestlers who competed in a similar number of matches, assuming experience to correlate
positively with skill.

As for the Elo algorithm, it is a computationally simple, yet highly flexible method. Elo treats prior ratings
as an indicator of wrestler strength, using the difference in ratings between competitors at the time of a
match to compute an expected probability of victory. Ratings after the match are adjusted based upon the
disparity between this expected result and the actual result, with more rating points earned for an upset than
a predictable win. We implement Elo rating in Python via the [Elote](https://pypi.org/project/elote/) package
by Will McGinnis. We take our parameter values for the Elo algorithm from the Bigsby and Ohlmann research
article, which suggests an initial rating of 1000 for each wrestler and a $K$ value, which determines the
ratings' sensitivity to a new match, of 225. While the initial rating parameter typically increases with the
size of the dataset, it has no effect on predictive accuracy. Meanwhile, the $K$ value typically has the
strongest effect on predictive accuracy, and therefore its value should be carefully selected through
precedent or cross-validation. The steps of the Elo algorithm, as implemented in the
[Elote](https://pypi.org/project/elote/) package by McGinnis, are the following (equations are written with
the opponent being the true loser of the match):

1. Transformed Current Rating: $R'=10^{R/R_{init}}$

$R$ is a wrestler's rating before the match, and $R_{init}$ is their initial rating.

2. Expected Result: $S_{exp}=\frac{R'}{R'+R'_{opp}}$

$S_{exp}$ can be interpreted as the probability of winning plus half the probability of drawing. The $opp$ subscript denotes a variable corresponding to the wrestler's opponent.

3. Update Rating (Winner): $R=R+K(1-S_{exp})$

4. Update Rating (Loser): $R_{opp}=R_{opp}+K(0-S^{exp}_{opp})$

$K$ is the aforementioned $K$ value; one can see its control over rating sensitivity via its
multiplicative nature in the update rating equations. Here we work through the Elo algorithm on an example
match to demonstrate its simplicity and utility for competitive rankings. Let our wrestlers be Wrestler A and
Wrestler B.

- Wrestler A has a rating of $R_A=500$ before the match
- Wrestler B has a rating of $R_B=400$ before the match
- $R_{init}=400$ and $K=32$

First, we calculate the wrestlers' transformed ratings, $R'_A$ and $R'_B$:

1. $R'=10^{R/R_{init}} \implies R'_A=17.78 \ , \ R'_B=10.00$

Wrestler A has a higher raw rating than Wrestler B, so it makes sense that their transformed rating does as
well. Next, we calculate the expected result:

2. $S_{exp}=\frac{R'}{R'+R'_{opp}} \implies S_{exp}=0.64$

Recall, $S_{exp}$ can be interpreted as the probability of winning plus half the probability of drawing. Thus,
we reasonably expect Wrestler A, with their higher pre-match rating, to be more likely to win the match.

At this point, the actual result of the match will determine how the ratings are updated. If Wrestler A wins
(as expected), they will take some points from Wrestler B:

3. $R=R+K(1-S_{exp}) \implies R_A=511.52$

4. $R_{opp}=R_{opp}+K(0-S^{exp}_{opp}) \implies R_B=388.48$

However, more points are exchanged if there is an upset. If Wrestler B wins despite his lower rating, they
will be rewarded for beating a tough opponent -- and Wrestler A will be equivalently punished for losing a
match they were expected to win:

3. $R=R+K(1-S_{exp}) \implies R_B=420.48$

4. $R_{opp}=R_{opp}+K(0-S^{exp}_{opp}) \implies R_A=479.52$

Note that even when Wrestler B upsets Wrestler A, he still has a lower rating after the match. If we wanted
the ratings to be more sensitive, increasing $K$ would increase how many points are exchanged as a result of
the match. 

As described and demonstrated above, one can see how the Elo algorithm's built-in control over sensitivity, ratings, and prediction make it a very promising technique for use in competitive wrestling. 

### Evaluation

- Predictive Accuracy
- Train and test sets

## Results and Follow-Up Analysis

- Acccuracy: Elo vs WP
- Certainty: Elo vs WP
- Predictive Accuracy (how good for how long)
- Special cases (few matches, cold starts, follow specific player, etc.)

## Discussion/Conclusion

- Elo vs WP
- Document difficulties
- Future work on code itself
- Future work in field
